---
title: "AI won't take your job (your boss will)"
date: 2025-01-16T08:53:32-05:00
image: robot-conqueror.png
image_attribution: Midjourney AI
---

AI is not going to replace the majority of programming jobs, full stop. I
roundly reject any argument that presents AI as a solution to converting a set
of business requirements into functioning software.

But, if you don't learn how to use AI, and stay abreast of what it can do, it
may very well replace YOU. Let me put that differently: it will be the reason
your boss replaces you.

<!--more-->
{{< dots >}}

"First, solve the problem. Then, write the code." I have tried very hard to live
by this adage for the better part of ten years, since I first heard it. In
today's software ecosystem, the hardest part of creating solutions isn't really
the programming, it's interpreting the requirements.

This has been true for a long time. Gary Sussman stopped teaching the legendary
MIT course based on his book with Hal Abelson, "The Structure and Interpretation
of Computer Programs," in 1997. The revelation they had then was that new
programmers didn't need to understand, nor could they understand, underlying
hardware or even common libraries anymore.

If that was true in 1997, it's even more true today. Now, a typical Node.js
application imports hundreds of modules, and no developer understands each and
every one of them. You don't need to understand how a filesystem works to read
and write files. You barely need to know what a filesystem is.

Sussman called it "programming by poking." Grab the puzzle pieces that provide
the basic functionality that your solution requires and figure out how to glue
them together. Sprinkle in a little bit of business logic and you're off to the
races. LLMs exploit the reality that the puzzle pieces have been glued together
millions of times by millions of people in full view of the internet, on GitHub
and StackOverflow and innumerable forums.

LLMs are also approximately as "smart" as a bag of rusty hammers. A glorified,
recursive Markov chain of library calls intuited from likely misleading (if not
outright incorrect) code comments and forum shitposts is not, in sum, a software
developer.

LLMs have been described as similar to "a junior-level software developer." If
you use an AI tool to help you write code, you have to review it as you would
the contributions of a less-experienced colleague. I buy that; I use GitHub
Copilot and it saves me a ton of typing time, but I still have to understand
what it's trying to do and whether it will work for my needs.

Only I understand the needs, because at least half of my job is spent figuring
out what my stakeholders actually want, which is quite often articulated in a
vague, incomplete, or misleading way. What a (well-meaning, intelligent,
experienced) person asks for is seldom what they actually need, once placed in
the context of a complex existing system, its architectural roadmap, and the
limitations of the laws of physics.

I can imagine no world in which a product manager types a list of acceptance
criteria into a prompt box and what pops out is working, maintainable,
well-tested, scalable software.

But if the existence of AI simply means access to nearly infinite junior
engineers, and even if the AI of a few years from now means access to nearly
infinite mid-level engineers, you'd better be ready to be the senior one in
charge of them. Vetting their assignments, reviewing their code, making the
puzzle pieces fit together in a sane way. The same work you're probably already
doing if you've been in the game for a while.

AI is going to make it a lot harder for entry-level engineers to land jobs. It's
also going to make it a lot easier for entry-level engineers to pump out code at
massive rates of speed. They'll still need to learn how to understand what it
does, whether it scales, how it should be tested... All the same things we
always had to learn.

In a way, AI might in fact raise the floor on the level that any human engineer
holds, because they do more and more of the things that only humans can do, and
less of the things that, let's be honest, they wish they didn't have to do.

GitHub Copilot has reduced my "search StackOverflow, find the top answer, and
paste the solution into my project" loop by hours. But right now, that's all it
can really do. It can write boilerplate for me, and I'm happy to have it do
that. It's like pairing with a new college grad. I still squint at everything
that comes out of it.

Maybe at some point it'll be like pairing with someone who's done the job for a
while and kind of "gets it." But it'll still never know what my PM means when
they write a one-sentence description of what a button should do, because I
barely know, either. Someone will always have to figure that out.

Make sure that someone is you.
